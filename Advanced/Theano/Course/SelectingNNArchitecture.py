

# Comparative betweeen algorithms:
#
#       PyData Paris 2016 - Automatic Machine Learning using Python & scikit-learn 
#       https://www.youtube.com/watch?v=_EviCgtzG7E


# Alway use SGD or ADAM (for fast convergence)
    
# Start slow
#   Single laye with 120-500 neurons
#   Batch Normalization + PreLU
#   Dropout: 10-20% (for overfitting)

# Add new layer:
#   1200-1500 neurons 
#   High Dropoup: 40-50%

#Very Big Network:
#   8000-10000 neurons 
#   High Dropoup: 60-80%



 